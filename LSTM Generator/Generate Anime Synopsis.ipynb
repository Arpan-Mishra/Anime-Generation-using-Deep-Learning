{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English\n",
    "import torch\n",
    "import spacy\n",
    "nlp = English()\n",
    "import torch.nn as nn\n",
    "import nltk\n",
    "pd.options.display.max_columns = 500\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Anime synopsis we have:  16610\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Data/eda-data.csv',index_col=0)\n",
    "synopsis = data.synopsis\n",
    "print('Number of Anime synopsis we have: ',len(synopsis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing some random synopsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synopsis example\n",
      "\n",
      "Anime:Two Tea Two \n",
      "Synopsis:The woman does the decision to coexist with the past.Returning to one person was not an answer. It is a new image.(Source: Official You Tube channel)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = random.randint(0,len(synopsis))\n",
    "print('Synopsis example\\n\\nAnime:{} \\nSynopsis:{}\\n'.format(data['anime_name'].values[i],synopsis.values[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_source(text):\n",
    "    cln_text = text\n",
    "    if '(Source' in cln_text:\n",
    "        cln_text,_,_ = cln_text.partition('(Source')\n",
    "    elif '[Written ' in cln_text:\n",
    "        cln_text,_,_ = cln_text.partition('[Written')\n",
    "        \n",
    "    return cln_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size:  7309\n"
     ]
    }
   ],
   "source": [
    "def clean_synopsis(data):\n",
    "    # removing hentai and kids tags\n",
    "    data = data[(data.Hentai != 1) & (data.Kids != 1)]\n",
    "    synopsis = data.synopsis\n",
    "    \n",
    "    # removing very small synopsis\n",
    "    synopsis = synopsis.apply(lambda x: x if ((len(str(x).strip().split())<=300) and len(str(x).strip().split())>30  ) else -1)\n",
    "    synopsis = synopsis[synopsis!=-1]\n",
    "    \n",
    "    # removing source text\n",
    "    synopsis = synopsis.apply(lambda x: remove_source(x))\n",
    "    \n",
    "    # removing japanese characters\n",
    "    synopsis = synopsis.apply(lambda x: re.sub(\"([^\\x00-\\x7F])+\",\" \",x))\n",
    "    \n",
    "    # remove symbols\n",
    "    rx = re.compile('^[&#/@`)(;<=\\'\"$%>]')\n",
    "    synopsis = synopsis.apply(lambda x: rx.sub('',x))\n",
    "    synopsis = synopsis.apply(lambda x: x.replace('>',\"\"))\n",
    "    synopsis = synopsis.apply(lambda x: x.replace('`',\"\"))\n",
    "    synopsis = synopsis.apply(lambda x: x.replace(')',\"\"))\n",
    "    synopsis = synopsis.apply(lambda x: x.replace('(',\"\"))\n",
    "    \n",
    "\n",
    "    # removing adaptation animes (some relevant might get deleted but there aren`t a lot so we wont be affected as much)\n",
    "    synopsis = synopsis[synopsis.apply(lambda x: 'adaptation' not in str(x).lower())]    \n",
    "    synopsis = synopsis[synopsis.apply(lambda x: 'music video' not in str(x).lower())]\n",
    "    synopsis = synopsis[synopsis.apply(lambda x: 'based on' not in str(x).lower())]\n",
    "    synopsis = synopsis[synopsis.apply(lambda x: 'spin-off' not in str(x).lower())]\n",
    "    \n",
    "    return synopsis.reset_index(drop=True)\n",
    "\n",
    "cleaned_synopsis = clean_synopsis(data)\n",
    "print('Size: ',len(cleaned_synopsis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:    \n",
    "    tokenizer = nltk.word_tokenize    \n",
    "    #data = AnimeDataset(cleaned_synopsis)\n",
    "    batch_size = 32\n",
    "    #vocab_size = data.vocab_size\n",
    "    seq_len = 30\n",
    "        \n",
    "    emb_dim = 100\n",
    "    epochs = 15\n",
    "    hidden_dim = 512\n",
    "    model_path = 'lm_lrdecay_drop.bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to create batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(synopsis,batch_size,seq_len):\n",
    "    np.random.seed(0)\n",
    "    synopsis = synopsis.apply(lambda x: str(x).lower()).values\n",
    "    synopsis_text = ' '.join(synopsis)\n",
    "    \n",
    "    \n",
    "    tokens = config.tokenizer(synopsis_text)\n",
    "    global num_batches\n",
    "    num_batches = int(len(tokens)/(seq_len*batch_size))\n",
    "    tokens = tokens[:num_batches*batch_size*seq_len]\n",
    "    \n",
    "    words = sorted(set(tokens))        \n",
    "    w2i = {w:i for i,w in enumerate(words)}\n",
    "    i2w = {i:w for i,w in enumerate(words)}\n",
    "    \n",
    "    tokens = [w2i[tok] for tok in tokens]\n",
    "    target = np.zeros_like((tokens))\n",
    "    target[:-1] = tokens[1:]\n",
    "    target[-1] = tokens[0]\n",
    "    \n",
    "    input_tok = np.reshape(tokens,(batch_size,-1))\n",
    "    target_tok = np.reshape(target,(batch_size,-1))\n",
    "    \n",
    "    print(input_tok.shape)\n",
    "    print(target_tok.shape)\n",
    "    \n",
    "    vocab_size = len(i2w)\n",
    "    return input_tok,target_tok,vocab_size,w2i,i2w\n",
    "\n",
    "def create_batches(input_tok,target_tok,batch_size,seq_len):\n",
    "    \n",
    "    num_batches = np.prod(input_tok.shape)//(batch_size*seq_len)\n",
    "    \n",
    "    for i in range(0,num_batches*seq_len,seq_len):\n",
    "        yield input_tok[:,i:i+seq_len], target_tok[:,i:i+seq_len]\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):    \n",
    "    def __init__(self,hid_dim,emb_dim,vocab_size,num_layers=1):\n",
    "        super(LSTMModel,self).__init__()\n",
    "        self.hid_dim = hid_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.vocab_size = vocab_size+1\n",
    "        self.embedding = nn.Embedding(self.vocab_size,self.emb_dim)\n",
    "        self.lstm = nn.LSTM(self.emb_dim,self.hid_dim,batch_first = True,num_layers = self.num_layers)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.linear = nn.Linear(self.hid_dim,vocab_size) # from here we will randomly sample a word\n",
    "        \n",
    "    def forward(self,x,prev_hid):\n",
    "        x = self.embedding(x)\n",
    "        x,hid = self.lstm(x,prev_hid)\n",
    "        x = self.drop(x)\n",
    "        x = self.linear(x)\n",
    "        return x,hid\n",
    "    \n",
    "    def zero_state(self,batch_size):\n",
    "        return (torch.zeros(self.num_layers,batch_size,self.hid_dim),torch.zeros(self.num_layers,batch_size,self.hid_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(predicted,target):\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    return loss(predicted,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model,device,dataloader,optimizer):\n",
    "    model.train()\n",
    "    tk0 = tqdm(dataloader,position=0,leave=True,total = num_batches)\n",
    "    train_loss = AverageMeter()  \n",
    "    hid_state,cell_state = model.zero_state(config.batch_size)\n",
    "    hid_state = hid_state.to(device)\n",
    "    cell_state = cell_state.to(device)\n",
    "    losses = []\n",
    "    for inp,target in tk0:\n",
    "                \n",
    "        inp = torch.tensor(inp,dtype=torch.long).to(device)\n",
    "        target = torch.tensor(target,dtype=torch.long).to(device)\n",
    "\n",
    "        optimizer.zero_grad()        \n",
    "        pred,(hid_state,cell_state) = model(inp,(hid_state,cell_state))\n",
    "        #print(pred.transpose(1,2).shape)\n",
    "        \n",
    "        loss = loss_fn(pred.transpose(1,2),target)\n",
    "        \n",
    "        hid_state = hid_state.detach()\n",
    "        cell_state = cell_state.detach()\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        _ = torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=2) # to avoid gradient explosion\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.update(loss.detach().item())\n",
    "        tk0.set_postfix(loss = train_loss.avg)\n",
    "        losses.append(loss.detach().item())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 25380)\n",
      "(32, 25380)\n"
     ]
    }
   ],
   "source": [
    "input_tok,target_tok,vocab_size,w2i,i2w = create_dataset(cleaned_synopsis,batch_size=config.batch_size,seq_len=config.seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing it all together in the run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    device = 'cuda'\n",
    "    model = LSTMModel(vocab_size=vocab_size,emb_dim=config.emb_dim,hid_dim=config.hidden_dim,num_layers=3).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, mode = 'min', patience=2, verbose=True, factor=0.5)\n",
    "    epochs = config.epochs\n",
    "    \n",
    "    best_loss = 999\n",
    "    for i in range(1,epochs+1):\n",
    "        train_dataloader = create_batches(batch_size=config.batch_size,input_tok=input_tok,seq_len=config.seq_len,target_tok=target_tok)\n",
    "        print('Epoch..',i)\n",
    "        loss = train_fn(model,device,train_dataloader,optimizer)\n",
    "        if loss<best_loss:\n",
    "            best_loss = loss\n",
    "            torch.save(model.state_dict(),config.model_path)\n",
    "        scheduler.step(loss)\n",
    "        torch.cuda.empty_cache()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:16<00:00,  4.30it/s, loss=7.24]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:17<00:00,  4.29it/s, loss=6.57]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.26it/s, loss=6.08]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.26it/s, loss=5.8]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:19<00:00,  4.25it/s, loss=5.59]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.26it/s, loss=5.41]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.25it/s, loss=5.24]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:19<00:00,  4.25it/s, loss=5.08]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:19<00:00,  4.25it/s, loss=4.93]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 846/846 [03:19<00:00,  4.23it/s, loss=4.8]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:19<00:00,  4.25it/s, loss=4.66]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.26it/s, loss=4.53]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.25it/s, loss=4.42]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.26it/s, loss=4.31]\n",
      "  0%|                                                                                          | 0/846 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch.. 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 846/846 [03:18<00:00,  4.27it/s, loss=4.21]\n"
     ]
    }
   ],
   "source": [
    "model = run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model,input_text,device,top_k=5,length = 100):\n",
    "    output = ''\n",
    "    model.eval()\n",
    "    tokens = config.tokenizer(input_text)\n",
    "        \n",
    "    h,c = model.zero_state(1)\n",
    "    h = h.to(device)\n",
    "    c = c.to(device)\n",
    "    \n",
    "    for t in tokens:\n",
    "        output = output+t+' '\n",
    "        pred,(h,c) = model(torch.tensor(w2i[t.lower()]).view(1,-1).to(device),(h,c))\n",
    "        #print(pred.shape)\n",
    "    for i in range(length):\n",
    "        _,top_ix = torch.topk(pred[0],k = top_k)\n",
    "               \n",
    "        choices = top_ix[0].tolist()                \n",
    "        choice = np.random.choice(choices)\n",
    "        out = i2w[choice]\n",
    "        output = output + out + ' '\n",
    "        pred,(h,c) = model(torch.tensor(choice,dtype=torch.long).view(1,-1).to(device),(h,c))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI generated Anime synopsis:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"In the days attempt it 's . although it has , however ! what they believe that humans of these problems . it seems and if will really make anything . as she must never overcome allowances with jousuke s , in order her home at him without it all in the world : in the hospital she makes him from himself by demons and carnage . a member and an idol team the power for to any means but the two come into its world for what if this remains was to wait in and is n't going ! on an \""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cpu'\n",
    "mod = LSTMModel(emb_dim=config.emb_dim,hid_dim=config.hidden_dim,vocab_size=vocab_size,num_layers=3).to(device)\n",
    "mod.load_state_dict(torch.load(config.model_path))\n",
    "print('AI generated Anime synopsis:')\n",
    "inference(model = mod, input_text = 'In the ', top_k = 30, length = 100, device = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
